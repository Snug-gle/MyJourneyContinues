## 1부 'LLM의 기초 뼈대 세우기'
  : 대규모 언어 모델이 지금까지 발전해 온 과정을 살핌
  1. 큰 흐름을 파악
  2. LLM의 기반이 되는 [[트랜스포머 아키텍처]] 이해 목표
  3. 트랜스포머 아키텍처 기반 모델을 활용할 수 있게 도와주는 '허킹페이스'의 트랜스포머 라이브러리 사용법 익히는 것을 목표
  4. OpenAI가 어떻게 챗GPT 같이 말 잘 듣는 모델을 만들었는지 확인
## 2부 'LLM 길들이기'
  : 언어 모델을 학습시키고 활용하는 데 필요한 기술을 다룸
  5. 용량이 큰 LLM을 작은 GPU에서도 학습시킬 수 있는 방법
  6. 'sLLM'을 실습 데이터로 학습시켜 자연어에서 SQL을 생성하는 'Text2SQL' 모델을 만들어 봄
  7. 비용 효율적으로 LLM을 서빙하기 위한 다양한 방법을 살핌
  8. LLM을 효율적으로 서빙할 수 있도록 도와주는 vLLM 라이브러리를 활용해 LLM을 서빙하는 방법을 알아봄
## 3부 'LLM을 활용한 실전 애플리케이션 개발'
  : LLM을 활용해 애플리케이션을 개발하는 방법을 살펴봄
  9. LLM 애플리케이션을 개발하기 위한 다양한 구성요소, 검색 증강 생성, LLM 캐시, 데이터 검증 등
  10. 검색 증강 생성에서 정보를 저장하고 검색할 때 사용하는 [[임베딩 모델]]에 대해 알아봄
  11. 검색 증강 생성을 활용하려는 데이터가 임베딩 모델을 학습할 때 사용되지 않은 기업의 내부 데이터이거나 최신의 데이터이면, 기존에 학습된 임베딩 모델을 활용할 경우 검색 성능이 만족스럽지 않음 -> 임베딩 모델을 자신의 데이터에 맞춰 추가 학습함으로써 검색 성능을 높일 수 있음, [[리랭커(Reranker)]] 활용하는 방법 알아봄
  12. 벡터 데이터베이스에서 활용되는 저장 및 검색 알고리즘인 HNSW(Hierarchical Navigable Small World)의 원리와 최적화 방법을 살펴봄, 대표적인 벡터 데이터베이스인 [[파인콘]] 을 활용해 멀티 모달 검색을 구현하는 실습 진행
  13. 머신러닝 모델을 효과적으로 운영하기 위해 사용하던 MLOps(Machine Learning Operations)를 LLM에 맞춰 확장한 [[LLMOps]]에 대해 알아봄
  14. '[[멀티 모달 LLM]]'에서는 텍스트 이외에 이미지를 처리하는 LLM에 대해 살펴봄. ex. OpenAI의 CLIP 모델(이미지, 텍스트 함께 처리), DALL-E 모델(텍스트 입력을 바탕으로 이미지를 생성), LLaVa(이미지와 텍스트를 함께 입력으로 받아 처리하는 오픈소스 모델) 
  15. LLM을 확장하는 에이전트 아키택처. ex. AutoGen
  16. 입력이 길어질 수록 추론에 많은 시간과 연산 비용이 드는 트랜스포머 아키텍처의 단점을 보완하기 위해 제안된 [[맘바(Mamba)아키텍처]]를 통해 새로운 아키텍처 가능성을 살펴봄
